# RAG Configuration for PDF Extractor

# LLM Configuration
llm:
  type: "anthropic"  # openai, anthropic, ollama
  # For Anthropic: claude-3-opus-20240229, claude-3-sonnet-20240229, claude-3-haiku-20240307,
  #               claude-3-5-sonnet-20241022, claude-3-5-haiku-20241022
  #               claude-4-opus, claude-4-sonnet, claude-4-haiku (when available)
  # For OpenAI: gpt-4, gpt-4-turbo, gpt-3.5-turbo, gpt-4o
  # For Ollama: llama2, llama3, mistral, codellama, o3, or any local model
  model: "claude-3-5-sonnet-20241022"  # Updated to latest available model
  temperature: 0.1
  max_tokens: 2000

# Vector Store Configuration
vector_store:
  type: "chromadb"
  path: "./data/vector_db"
  collection_name: "technical_docs"

# Embedding Configuration
embedding:
  model: "sentence-transformers/all-MiniLM-L6-v2"
  chunk_size: 512
  chunk_overlap: 50

# Retrieval Configuration
retrieval:
  top_k: 5
  similarity_threshold: 0.7

# Chunking Strategy
chunking:
  strategy: "sections"  # sections, tokens, patterns
  max_tokens: 512
  overlap_tokens: 50

# Logging Configuration
logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s" 